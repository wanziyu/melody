apiVersion: melody.io/v1alpha1
kind: Inference
metadata:
  name: inference-sample
spec:
  domain: time-series-prediction
  servingTemplate:
    metadata: { }
    template:
      metadata: { }
      spec:
        containers:
          - name: elasticjob-worker
            image: wanziyu/imagenet:1.1
            imagePullPolicy: Always
            args:
              - "--nproc_per_node=1"
              - "/workspace/examples/imagenet/main.py"
              - "--arch=resnet50"
              - "--epochs=1"
              - "--batch-size=64"
              - "--print-freq=50"
              # number of data loader workers (NOT trainers)
              # zero means load the data on the same process as the trainer
              # this is set so that the container does not OOM since
              # pytorch data loaders use shm
              - "--workers=0"
              - "/workspace/data/tiny-imagenet-200"
              - "--checkpoint-file=/mnt/blob/data/checkpoint.pth.tar"
            resources:
              limits:
                nvidia.com/gpu: 1
           # volumeMounts:
           #   - name: trainingdata
            #    mountPath: "/mnt/blob/data"
     # volumes:
      #  - name: trainingdata
        #  persistentVolumeClaim:
        #    claimName: pvc-torch-checkpoint
  clientTemplate:
    metadata:
      name: batch-job
    spec:
      backoffLimit: 1
      template:
        metadata: { }
        spec:
          restartPolicy: OnFailure
          containers:
            - name: man
              image: luksa/batch-job
